{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CK+Tr_JAFFE.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8MU-q7Qn8BBq","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTbs_pzPgB-o","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu==1.15\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQTTFnzhDmEz","colab_type":"code","colab":{}},"source":["#input grayscale\n","#0. Import libraries\n","#. crop images+ spilit into trainset, valiset, testset arrays\n","# Import libraries# Impor \n","import os,cv2\n","import random\n","# import a classifier object\n","from sklearn.svm import LinearSVC\n","from numpy import zeros, newaxis\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from pylab import rcParams\n","#import PIL\n","#print(PIL.PILLOW_VERSION)\n","import glob\n","import socket\n","import csv\n","import pandas as pd\n","import keras\n","from sklearn.utils import shuffle\n","from keras.utils.np_utils import to_categorical\n","from keras import utils as np_utils\n","from keras.models import Sequential\n","\n","#from tflearn.layers.conv import conv_2d, max_pool_2d\n","from keras.layers import Dropout\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.models import load_model\n","from keras.preprocessing import image\n","\n","import tensorflow as tf\n","import keras\n","from keras.utils import np_utils\n","from keras import backend as K\n","from keras import callbacks\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","#ada\n","from keras.optimizers import SGD,Adadelta\n","\n","#network\n","from keras import backend as K\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D\n","from keras.optimizers import SGD,RMSprop,adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import KFold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LwJ0X8zNSW7","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense\n","from tensorflow.python.keras import Sequential\n","from tensorflow.python.keras.utils.data_utils import Sequence\n","\n","from keras.layers.normalization import BatchNormalization\n","import numpy as np\n","np.random.seed(1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"66CYWIPjSrJO","colab_type":"code","colab":{}},"source":["#1. Define dataload\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import random\n","import keras.backend as K\n","\n","emotion_list = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sadness\", \"surprise\"] \n","n_classes = len(emotion_list)\n","\n","class DataGenerator(Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_imgs, batch_size=32, dim=(3, 48, 48), n_channels=3\n","                        , shuffle=True):\n","        'Initialization'\n","        #print(list_imgs)\n","        #print(type(list_imgs))\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.list_imgs = list_imgs\n","        random.shuffle(self.list_imgs)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_imgs) // self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        img_path = self.list_imgs[index]\n","        img = cv2.imread(img_path)\n","        mapping = {}\n","        y = 9\n","        #print(\"len(emotion_list): \",len(emotion_list))\n","        for x in range(len(emotion_list)):\n","          if emotion_list[x] in str(img_path):\n","            y = x\n","          #  print(\"y: \",y)\n","        #print(y)\n","        #print(num_classes)\n","        #print(img_path)\n","        img = cv2.resize(img, (32, 32))\n","        img = img[ newaxis,:, :, :]\n","        img = (np.array(img))\n","\n","        #img = tf.keras.backend.expand_dims(img, axis=0)\n","        #print(\"img shape: \",img.shape)\n","        # y = keras.utils.to_categorical(y, num_classes=self.n_classes)\n","        #print(y)\n","        y_label = list()\n","        y_label.append(y)\n","        y_label = np.asarray(y_label)\n","        #print(\"++++++++++++++++++++++++\")\n","        return (img , y_label)\n","        \n","      \n","    def on_epoch_end(self):\n","      'Updates indexes after each epoch'\n","      self.index = np.arange(len(self.list_imgs))\n","      if self.shuffle == True:\n","        np.random.shuffle(self.index)\n","    #Data generators\n","\n","# Generators\n","image_folder = \"ALL CK+\"\n","original_folder = \"/content/gdrive/My Drive/Machine learing/Pre-process/Data Ck plus/ALL CK+\"\n","#main_folder =os.listdir(original_folder)\n","list_name_img = os.listdir(original_folder)\n","#list_name_img = next(os.walk(original_folder))[2]\n","#list_name_img = os.listdir(original_folder)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVaiDzAwmk2s","colab_type":"code","colab":{}},"source":["#2. load list_imgs\n","nb_img = 0\n","list_imgs = []\n","for img_load in list_name_img:\n","  img_path = original_folder + \"/\" + img_load\n","  list_imgs.append(img_path)\n","  nb_img +=1\n","  #print(\"nb_img \",nb_img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFU7pu1bnBi3","colab_type":"code","colab":{}},"source":["print(len(list_imgs))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAM4EesXE8rZ","colab_type":"code","colab":{}},"source":["#code dot nhien ko chay nen chinh thanh cai ben tren\n","nb_img = 0\n","list_imgs = list()\n","for img in list_name_img:\n","    if \".png\" in img:\n","        img_path = os.path.join(original_folder, img)\n","        list_imgs.append(img_path)\n","        nb_img +=1\n","\n","#labels = map(lambda x: dict(enumerate(data['target_names']))[x], data['target'])\n","\n","# randomly shuffle list_imgs\n","list_imgs = random.shuffle(list_imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPa_q7McieUM","colab_type":"code","colab":{}},"source":["print(list_imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWuevp_0sIi4","colab_type":"code","colab":{}},"source":["#labels = DataGenerator.__getitem__(list_imgs)\n","labels =[]\n","print(\"run training_generator: \")\n","training_generator = DataGenerator(list_imgs=list_imgs)\n","print(\"run validation_generator: \")\n","validation_generator = DataGenerator(list_imgs=list_imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWsjni8u2Fy6","colab_type":"code","colab":{}},"source":["print(nb_img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xodrkCKBuR9I","colab_type":"code","colab":{}},"source":["#3. Design model\n","num_classes = 8\n","model = Sequential()\n","from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, Dense, Input\n","from keras.layers import BatchNormalization\n","from tensorflow.keras import activations\n","\n","#add kernel_regularizer=l2(0.0005) neu overfitting\n","model.add(Conv2D(32, (5, 5),strides=(1,1), padding=\"valid\", activation=\"relu\",\n","                input_shape=[32,32,3]))\n","model.add(Dropout(0.2))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(2, (7,7),strides=(1,1),activation =\"relu\",\n","                padding=\"valid\"))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dropout(0.2))\n","model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7oSrWPrSuqsi","colab_type":"code","colab":{}},"source":["#4. Compile\n","model.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGLCrnA2yBSN","colab_type":"code","colab":{}},"source":["model.fit_generator(generator=training_generator,\n","                    validation_data = validation_generator,  epochs=100)\n","                    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnhDEn73C1J7","colab_type":"code","colab":{}},"source":["#5. Run fit+ K-fold\n","k = 10\n","len_each_fold = len(list_imgs) // k\n","for i in range(k-1):\n","  print(\"Fold chay thu: \",(i+1))\n","  list_img_val = list_imgs[i*len_each_fold: (i+1)*len_each_fold]\n","  list_img_train = list(set(list_imgs) - set(list_img_val))\n","  print(\"run training_generator: \")\n","  training_generator = DataGenerator(list_imgs=list_img_train)\n","  print(\"run validation_generator: \")\n","  validation_generator = DataGenerator(list_imgs=list_img_val)\n","  model.fit_generator(generator=training_generator,\n","                    validation_data = validation_generator, epochs=1000)\n","  print(\"+++++++++++++++++++++++++++\")\n","  print(\" \")\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtLLAgPzDNvB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hk2xwT0UzhfN","colab_type":"code","colab":{}},"source":["#@5. Main code\n","#Function\n","#Define k-fold-link: Load link data train, val data\n","#nb_fold la so vong fold se dung\n","#def k_fold_link(all_img_link,nb_fold):\n","nb_fold =10\n","link_data_val =[]\n","n = 0\n","x=[]\n","mean = 0\n","val_data = []\n","train_data = []\n","#Chia val_train data theo k-fold\n","k = len()\n","for n in range(0,nb_fold):\n","  divide_f = int(nb_img/nb_fold)\n","  fl_val= divide_f*(n+1)-1\n","  start_val = divide_f*n\n","  start_train = divide_f*(n+1)\n","  print(fl_val)\n","  x.append(source_img[start_val:fl_val])\n","  #Gia tri val_data, train_data voi divide_f phan tu\n","  fl_nb_val = divide_f-1\n","  fl_nb_train = nb_img-divide_f-1\n","  val_data[0:fl_nb_val]= (source_img[start_val:fl_val]) \n","  train_data[0:fl_nb_train] = source_img[start_train:(nb_img-1)]\n","  #Chay train_generator\n","  \n","  #Chay val_generator\n","  \n","  print(\" n la \",n)\n","  print(val_data)\n","  n=n+1\n","  #run fit\n","  #x_train, y_train =train_generator(val_data[0:fl_nb_train],(fl_nb_train+1))\n","  hist = model.fit(train_generator(val_data[0:fl_nb_train],(fl_nb_train+1)), epochs=10)                 \n","  #evaluation\n","  #x_val, y_val =val_generator(val_data[0:fl_nb_val],(fl_nb_val+1))\n","  score, accuracy =(model.evaluate(val_generator(val_data[0:fl_nb_val],(fl_nb_val+1))))\n","  print(\"Acurracy on validation data: \",model.evaluate(val_generator(val_data[0:fl_nb_val],(fl_nb_val+1))) )\n","  if n==1:\n","    mean = accuracy\n","  else:\n","    mean = (accuracy+ mean)/2\n","    print(\" Mean Accurracy: \", mean)\n","    \n","#k_fold_link(source_img, 10)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"48dS7o6fDult","colab_type":"code","colab":{}},"source":["score, accuracy =(model.evaluate(x_val, y_val))\n","print(score)\n","print(accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZK2xv9Cd2cX","colab_type":"code","colab":{}},"source":["#6.save model\n","model.save('PP_CK+Tr_JAFFE.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"38LPvMwZd-zn","colab_type":"code","colab":{}},"source":["import shutil\n","shutil.copy('/content/PP_CK+Tr_JAFFE.h5', '/content/gdrive/My Drive/Machine learing/Test/Final Pr_3/Result/model') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_azHF4_feZy","colab_type":"code","colab":{}},"source":["reloaded_model = tf.keras.models.load_model('/content/gdrive/My Drive/Machine learing/Test/Final Pr_3/Result/model/PP_CK+Tr_JAFFE.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyoEs-p244cv","colab_type":"code","colab":{}},"source":["#7. Evaluation\n","print(\"Evaluate on the test data: \\n\")\n","results = reloaded_model.evaluate(x_test, y_test)\n","print(\"test loss, test accuracy\", results)\n","#print(\"y test: \", y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lp5mOMnwU1PX","colab_type":"code","colab":{}},"source":["#9. Draw matrix result\n","#9.1.Luu test samples da dung truoc do\n","np.save('modXtest',x_test)\n","np.save('modytest',y_test)\n","#9.2.Load du lieu \n","truey=[]\n","predy=[]\n","x= np.load('./modXtest.npy')\n","y= np.load('./modytest.npy')\n","ypredict = reloaded_model.predict(x)\n","results_reload = reloaded_model.evaluate(x, y)\n","print(\"test loss, test accuracy\", results_reload)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TixRt26JztpN","colab_type":"code","colab":{}},"source":["import numpy as np\n","print(\"x shape: \", x.shape)\n","print(\"x 0: \", x[0].shape)\n","# print(\"y predict: \", ypredict)\n","print(\"y predict shape: \", ypredict.shape)\n","#  lay label\n","y_result = np.argmax(ypredict, axis=1) \n","print(\"y result shape:\", len(y_result))\n","print(\"y result: \", y_result)\n","y_label = [np.argmax(x) for x in y]\n","print(\"y_label: \", y_label)\n","predy = y_result\n","true_y = y_label \n","\n","np.save('truey', y_label)\n","np.save('predy', y_result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYCJIxyHgcIQ","colab_type":"code","colab":{}},"source":["#10. Ve matran\n","import itertools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","y_true = np.load('./truey.npy')\n","y_pred = np.load('./predy.npy')\n","cm = confusion_matrix(y_true, y_pred)\n","labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","title='Confusion matrix'\n","print(cm)\n","\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title(title)\n","plt.colorbar()\n","tick_marks = np.arange(len(labels))\n","plt.xticks(tick_marks, labels, rotation=45)\n","plt.yticks(tick_marks, labels)\n","fmt = 'd'\n","thresh = cm.max() / 2.\n","for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, format(cm[i, j], fmt),\n","            horizontalalignment=\"center\",\n","            color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.tight_layout()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGNLz8Q22wa5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}